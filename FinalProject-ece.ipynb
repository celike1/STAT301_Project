{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a86b37bb-03ae-40e2-956c-1f449cdfd00f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# STAT 301 Final Project\n",
    "**Eric Liu**,\n",
    "**Ece Celik**, \n",
    "**Herman** ,\n",
    "**Holly** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9954c5-368b-4747-99a4-17d791ea2f26",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "​​In the dynamic landscape of technology employment, recent trends have shown significant fluctuations in job stability. Notably, the first half of 2023 witnessed an alarming figure of over 300,000 layoffs in tech companies. This period of uncertainty, however, seems to be transitioning, as indicated by Bernstein analysts.(Bernstein analysts, 2023) Their recent communication with clients optimistically noted, \"The Tech Job Recession is Over,\" pointing toward a slowdown in layoffs and raising questions about the timing of hiring resurgences.\n",
    "\n",
    "This shift in the tech employment sector lays the foundation for our project, which delves into the intricacies of salary determinants in the data science field. Our research aims to unravel how various factors, including a company's location, its size, the experience level of employees, employment type, remote working ratio, and the work year, influence the salary of entry-level data scientists.\n",
    "\n",
    "The question that we will try to answer in this project is: **How do location of a company, company size, experience level of an employee, employment type, remote working ratio and work year predict the salary of data science related positions?**\n",
    "\n",
    "Our project is rooted in a comprehensive dataset from Kaggle, titled \"Data Science Job Salaries\" (link: https://www.kaggle.com/datasets/ruchi798/data-science-job-salaries). This dataset, aggregated by ai-jobs.net, offers a detailed view of the salaries within the data science domain, despite the inactive data source link (salaries.ai-jobs.net).\n",
    "\n",
    "To answer our quesiton we will be using `company_location`, `company_size`, `experience_level`, `employment_type`, `job_title`, `employee location`,`remote_ratio`, `work_year` and `salary` variables from the dataset. The delailed explanation of these variables can be found in the section below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28726798-7479-4d07-9218-53661d42ff55",
   "metadata": {},
   "source": [
    "## Preliminary Observations & Variables\n",
    "\n",
    "The Kaggle dataset that will be used in this project has 607 rows and 12 columns including and id column. The other 11 columns include four quantitative, five categorical and two ordinal variables. Their detailed descriptions are shown below:\n",
    "\n",
    "* work_year: The year the salary was paid. The range of this data is from 2020-2022. This is a quantitative explanatory variable. </br>\n",
    "\n",
    "* experience_level: Level of experience  in the job during the year. This variable is a ordinal explanatory varibale.The possible values are: </br>\n",
    "  EN = Entry-level / Junior  </br>\n",
    "  MI = Mid-level / Intermediate </br>\n",
    "  SE = Senior-level / Expert </br>\n",
    "  EX = Executive-level / Director </br>\n",
    "  \n",
    "* employment_type: Type of employement. This is a categorical explanatory varibale. The possible values are: </br>\n",
    "  PT = Part-time  </br>\n",
    "  FT = Full-time  </br>\n",
    "  CT = Contract </br>\n",
    "  FL = Freelance </br>\n",
    "\n",
    "* job_title: Position title during the year. This is a categorical explanatory variable. There 50 different values possible for every different Data Science position. The values include (Data Scientist, Machine Learning Scientist, Big Data Engineer etc.) </br>\n",
    "\n",
    "* salary: Total gross salary amount paid. This is the quantitative **response** variable that ranges from 4000 to 30400000 </br>\n",
    "\n",
    "* salary_currency: Currency of the salary paid represented as ISO 4217 currency code. This is a categorical explanatory variable. It has 17 different values. The values include 'EUR','USD','GBP' etc. </br>\n",
    "\n",
    "* salary_in_usd: Salary in USD (FX rate divided by avg. USD rate for the respective year via fxdata.foorilla.com). This is a quantitative exploratory variable that ranges from 2859 to 600000.</br>\n",
    "\n",
    "* employee_residence: Employee's primary country of residence in during the work year represented as ISO 3166 country code. This is a categorical explanatory varibale. It has 57 different values. The values include 'AU','BO','IE','CH' etc. </br>\n",
    "\n",
    "* remote_ratio = Overall amount of work done remotely. This is quantitative explanatory variable. The possible values are: </br>\n",
    " 0 = No remote work (less than 20%)</br>\n",
    " 50 = Partially remote </br>\n",
    " 100 =  Fully remote (more than 80%) </br>\n",
    "\n",
    "* company_location = Country of the employer's main office or contracting branch as an ISO 3166 country code. This is categorical explanatory variable. It has 50 different values. The values include 'DE','JP','GB' etc. </br>\n",
    "\n",
    "* company_size = Average number of people that worked for the company during the year. This  is a ordinal explanatory varibale. The possible values are: </br>\n",
    "  S = less than 50 employees (small) </br>\n",
    "  M = 50 to 250 employees (medium) </br>\n",
    "  L = more than 250 employees (large) </br>\n",
    "\n",
    "In addition, there does not seem to be any immediate missing values in the columns.\n",
    "    \n",
    "The dataset contains:\n",
    "- **3** continuous numerical columns: `work_year`, `salary`, `salary_in_usd`\n",
    "- **4** categorical variables: `job_title`, `salary_currency`, `employee_residence`, `company_location`\n",
    "- **4** ordinal variables: `experience_level`, `employment_type`,`remote_ratio`, `company_size`\n",
    "- There are zero NA/empty values in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d17d4e-6c77-43d7-bc46-76f5fc6a37a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2af242b8-313f-4dd4-b84c-1c5633e9b899",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching core tidyverse packages\u001b[22m ──────────────────────── tidyverse 2.0.0 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdplyr    \u001b[39m 1.1.3     \u001b[32m✔\u001b[39m \u001b[34mreadr    \u001b[39m 2.1.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mforcats  \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mstringr  \u001b[39m 1.5.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2  \u001b[39m 3.4.4     \u001b[32m✔\u001b[39m \u001b[34mtibble   \u001b[39m 3.2.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mlubridate\u001b[39m 1.9.3     \u001b[32m✔\u001b[39m \u001b[34mtidyr    \u001b[39m 1.3.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mpurrr    \u001b[39m 1.0.2     \n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[36mℹ\u001b[39m Use the conflicted package (\u001b[3m\u001b[34m<http://conflicted.r-lib.org/>\u001b[39m\u001b[23m) to force all conflicts to become errors\n",
      "── \u001b[1mAttaching packages\u001b[22m ────────────────────────────────────── tidymodels 1.0.0 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mbroom       \u001b[39m 1.0.5     \u001b[32m✔\u001b[39m \u001b[34mrsample     \u001b[39m 1.1.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdials       \u001b[39m 1.1.0     \u001b[32m✔\u001b[39m \u001b[34mtune        \u001b[39m 1.0.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34minfer       \u001b[39m 1.0.4     \u001b[32m✔\u001b[39m \u001b[34mworkflows   \u001b[39m 1.1.2\n",
      "\u001b[32m✔\u001b[39m \u001b[34mmodeldata   \u001b[39m 1.0.1     \u001b[32m✔\u001b[39m \u001b[34mworkflowsets\u001b[39m 1.0.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mparsnip     \u001b[39m 1.0.3     \u001b[32m✔\u001b[39m \u001b[34myardstick   \u001b[39m 1.1.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mrecipes     \u001b[39m 1.0.8     \n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ───────────────────────────────────────── tidymodels_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mscales\u001b[39m::\u001b[32mdiscard()\u001b[39m masks \u001b[34mpurrr\u001b[39m::discard()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m   masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mfixed()\u001b[39m  masks \u001b[34mstringr\u001b[39m::fixed()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m      masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[31m✖\u001b[39m \u001b[34myardstick\u001b[39m::\u001b[32mspec()\u001b[39m masks \u001b[34mreadr\u001b[39m::spec()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mstep()\u001b[39m   masks \u001b[34mstats\u001b[39m::step()\n",
      "\u001b[34m•\u001b[39m Dig deeper into tidy modeling with R at \u001b[32mhttps://www.tmwr.org\u001b[39m\n",
      "\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in library(mltools): there is no package called ‘mltools’\n",
     "output_type": "error",
     "traceback": [
      "Error in library(mltools): there is no package called ‘mltools’\nTraceback:\n",
      "1. library(mltools)"
     ]
    }
   ],
   "source": [
    "# Load required libraries\n",
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(tidymodels)\n",
    "library(broom)\n",
    "library(mltools)\n",
    "library(leaps)\n",
    "library(data.table)\n",
    "library(\"gridExtra\")\n",
    "library(\"cowplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aef7a38-0849-4354-82b5-3b4898df088d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load dataset from online\n",
    "data <- read.csv(\"https://raw.githubusercontent.com/celike1/STAT301_Project/main/ds_salaries.csv\", row.names = 1)\n",
    "head(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95eca815-d178-49c9-b956-635e32c3adae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in apply(data, 2, function(x) any(is.na(x))): dim(X) must have a positive length\n",
     "output_type": "error",
     "traceback": [
      "Error in apply(data, 2, function(x) any(is.na(x))): dim(X) must have a positive length\nTraceback:\n",
      "1. apply(data, 2, function(x) any(is.na(x)))",
      "2. stop(\"dim(X) must have a positive length\")"
     ]
    }
   ],
   "source": [
    "# Check for Missing values\n",
    "apply(data, 2, function(x) any(is.na(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aac8bd6-1594-4794-9169-9229b98bf085",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function (..., list = character(), package = NULL, lib.loc = NULL, verbose = getOption(\"verbose\"), \n",
      "    envir = .GlobalEnv, overwrite = TRUE)  \n"
     ]
    }
   ],
   "source": [
    "glimpse(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b411827b-d12e-424c-9d40-8c9581282ff9",
   "metadata": {},
   "source": [
    "**Dropping un-used columns, changing characters to factors**\n",
    "\n",
    "Salary and salary_currency were also not included because we thought that having one shared salary type (salary_in_usd) would be easier for comparison purposes. Since we use a common salary in usd we do not have to do any convertions considering different currencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8831992e-99e1-4af2-9e4d-0d672dd9c4a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data <- data %>% \n",
    "    mutate_if(sapply(data, is.character), as.factor) %>% \n",
    "    select(-c(salary,salary_currency))\n",
    "glimpse(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3541dc99-386c-4f48-a6c3-eb6b99955d3d",
   "metadata": {},
   "source": [
    "**Renaming values to understandable strings**\n",
    "\n",
    "Some of the level names in some variables are hard to understand. We will rename levels of `employment type`, `experience level` and `remote_ratio` so that our plots can have more meaningful and understandable level labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4607dd-d7ea-42f9-b1e6-e339a0ee2042",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data <- data %>% \n",
    "    mutate(experience_level = recode(experience_level, EN = \"Entry/Junior\", \n",
    "                                                       MI = \"Mid-level\", \n",
    "                                                       SE = \"Senior/Expert\", \n",
    "                                                       EX = \"Executive\")) %>% \n",
    "    mutate(employment_type = recode(employment_type, PT = \"Part-Time\", \n",
    "                                                     FT = \"Full-Time\", \n",
    "                                                     CT = \"Contract\", \n",
    "                                                     FL = \"Freelance\")) %>%  \n",
    "    mutate(remote_ratio = recode_factor(remote_ratio, '0'= \"Stationary\", \n",
    "                                                      '50' = \"Partially remote\", \n",
    "                                                      '100' = \"Remote\")) \n",
    "\n",
    "glimpse(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bbb595-dff7-404d-80ff-18bf02687089",
   "metadata": {},
   "source": [
    "**Summary Statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707e4254-ac62-4a18-9a66-269c7d0d6317",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "summary(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb89792-2f10-4df5-b4d5-1ae4d9df9ee3",
   "metadata": {},
   "source": [
    "Then we subset the columns into 3 groups: **Categorical, Numeric, Ordinal** for future use in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33dae97-8c03-4dc0-bd96-739a5ee271ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Group Columns\n",
    "cat_colnames <- c('employment_type', 'job_title', 'employee_residence', 'company_location')\n",
    "num_colnames <- c('work_year', 'salary_in_usd', 'remote_ratio')\n",
    "ord_colnames <- c('experience_level', 'company_size')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e5c686-6158-401d-b2b9-fdaad3c67020",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784354dd-245a-48ca-971f-7ba39d6743cd",
   "metadata": {},
   "source": [
    "The question we posed in this assignment was:\n",
    "**How do location of a company, company size, experience level of an employee, employment type, remote working ratio and work year predict the salary of data science related positions?**\n",
    "\n",
    "Socially we know that usually a higher salary correlates to variables such as `experience_level`. By creating preliminary histograms, one for each unique value of the variable, we can get a informative view of the distribution of salaries. This helps us formulate hypotheses to whether or not they will have a positive or negative effect in our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c62e00-29ac-4875-8832-2e6d0c367b7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=6, repr.plot.height=6)\n",
    "\n",
    "p1 <- ggplot(data) +\n",
    "    geom_histogram(aes(x = salary_in_usd), binwidth = 10000) +\n",
    "    xlab(\"Salary of each Job (in USD)\") +\n",
    "    ylab(\"Count of Jobs\") +\n",
    "    ggtitle(\"Figure 1. Distribution of Data Science Salaries\") + \n",
    "    scale_x_continuous(labels = scales::comma) +\n",
    "    theme(text = element_text(size=12))\n",
    "plot(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ec0f80-37d0-4f5f-a071-9efae4e1286a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=10, repr.plot.height=8)\n",
    "\n",
    "# Plotting each Distribution\n",
    "p2 <- ggplot(data) +\n",
    "    geom_histogram(aes(x = salary_in_usd), binwidth = 10000) +\n",
    "    xlab(\"Salary of each Job (in USD)\") +\n",
    "    ylab(\"Count of Jobs\") +\n",
    "    ggtitle(\"Figure 2. Distribution of Data Science Salaries Across Experience Levels\") + \n",
    "    facet_wrap(~experience_level, scale=\"free\") +\n",
    "    scale_x_continuous(labels = scales::comma) +\n",
    "    theme(text = element_text(size=12))\n",
    "plot(p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a57f64b-5e54-4905-8dbd-41e4aa164d47",
   "metadata": {},
   "source": [
    "Although this is very preliminary plotting, it gives us some insights about the trends and values in the `experience_level` explanatory variable such as:\n",
    "- We see that general range of salaries for each of the 4 experience level groups\n",
    "- We see that the median/mean salaries seem to increases positively with experience level\n",
    "- We see the distribution values in the dataset to each experience levels (Which group is represented more/less)\n",
    "- We can see that the *Executive* group contains fewer values than the rest, this asymmetry should considered during model creation.\n",
    "\n",
    "This information allows us to create hypotheses so that we can verify and test if our model makes sense, and catch issues early such as the uneven counts in each group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320de35b-13e2-4011-bac9-e7f2ad0ec1af",
   "metadata": {},
   "source": [
    "We continue to explore our dataset by creating multiple boxplots plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1bf308-7373-498f-801e-ef81b82560c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 20, repr.plot.height = 16)\n",
    "library(gridExtra)\n",
    "\n",
    "\n",
    "plot_all1<- ggplot(data, aes(x = factor(work_year), y = salary_in_usd, fill = experience_level)) +\n",
    "  geom_boxplot() +\n",
    "  labs(x = \"Work Year\", y = \"Salary in USD\") +\n",
    "  ggtitle(\"Plot 1: Boxplot of Salary by Work Year for All Experience Levels \")\n",
    "\n",
    "plot_all2<- ggplot(data, aes(x = company_size, y = salary_in_usd, fill = experience_level)) +\n",
    "  geom_boxplot() +\n",
    "  labs(x = \"Company Size\", y = \"Salary in USD\") +\n",
    "  ggtitle(\"Plot 2: Boxplot of Salary by Company Size for All Experience Levels \") +\n",
    "  theme(text = element_text(size=12))\n",
    "\n",
    "plot_all3<- ggplot(data, aes(x = employment_type, y = salary_in_usd, fill = experience_level)) +\n",
    "  geom_boxplot() +\n",
    "  labs(x = \"Employment Type\", y = \"Salary in USD\") +\n",
    "  ggtitle(\"Plot 3: Boxplot of Salary by Employment Type for All Experience Levels \") +\n",
    "  theme(text = element_text(size=12))\n",
    "  \n",
    "\n",
    "plot_all4<- ggplot(data, aes(x = remote_ratio, y = salary_in_usd, fill = experience_level)) +\n",
    "  geom_boxplot() +\n",
    "  labs(x = \"Remote Ratio\", y = \"Salary in USD\") +\n",
    "  ggtitle(\"Plot 4: Boxplot of Salary by Remote Ratio for All Experience Levels \") +\n",
    "  theme(text = element_text(size=12))\n",
    "\n",
    "\n",
    "\n",
    "grid.arrange(plot_all1, plot_all2, plot_all3, plot_all4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bb5976-41d3-43bc-8ec7-66d1e32aff77",
   "metadata": {},
   "source": [
    "All of these plots are relevent to address our question and explore the data because:\n",
    "\n",
    "- Plot 1: One of the variables that we are trying to explore is work year and how the distribution of salary changes across different years. In Plot 1, we plot boxplots for last 3 years for all experience levels. This can give us an insight about whether a specific year had mostly higher or lower salaries for all levels. For example, in the case of a global economic crisis, it is likely that every experience level will receive a lower salary than other years. In Plot 1 we observe that in the last 3 years most experience levels received similar salaries and there has not been a significant increase or decrease.\n",
    "\n",
    "- Plot 2: In plot 3, we are specifically trying to see which company size is giving the hughest salary for Entry-level / Junior Positions. From this plot, we can see that small and large companies have a very similar range for  Entry-level / Junior Positions. This plot is only plotted for Entry-level/ Junior position because we expected to have an increase in other expreience levels' salries as the company size got bigger.\n",
    "\n",
    "- Plot 3: This plot communicates that in our dataset there is not enough data for Senior and Executive for Conract, Freelance and Part-time emplyment types. In addition for Entry/Junior and Mid-level experience levels, Full-Time positions have slightly higher salary than Part-time positions.\n",
    "\n",
    "- Plot 4: We observe that Executive and Senior/Expert experience level salaries are larger when the position is fully remote. There is no substantial increase in the salaries of Entry/Junior and Mid-level experience levels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059a1b36-935a-4432-90b0-45238b44a3d3",
   "metadata": {},
   "source": [
    "# Methods Plan\n",
    "\n",
    "We noticed early on (and in EDA) that this dataset contains a considerable amount of categorical variables. However, in the context of our investigative question and the course material, we know that a **linear regression** model would fit best. Therefore, we have decided to perform two analyses to not only test the accuracy of each model, but also to investigate the benefits or risks of variable selection for datasets like this:\n",
    "1. **MLR** without variable selection\n",
    "2. **MLR** with one-hot-encoding and **backwards-variable selection**\n",
    "This allows us to compare the $R^2$ and adjusted $R^2$ values to see which model may be a better approach.\n",
    "\n",
    "> **Why is this method appropriate?**\n",
    "\n",
    "As the goal question is to predict expected `salary_in_usd` while determining which explanatory variables are relevant, we feel an MLR allows us to test across multiple variables which may have a possible effect. Likewise, the coefficients and errors of each variable from the model, will allows us to see which has the greatest positive or negative effect. A notable step for both prediction MLR models is the split between `training` and `testing` data, which we have chosen to be approximately 30:70, to ensure we have an adequate sample size for both. This is done through the `initial_split()` function. After we produce the models of interest we will compute the Root-Mean Squared Error (RMSE) to determine how accurate our model is to the unseen data, similarly comparing the two models.\n",
    "\n",
    "> **Which assumptions are required, if any, to apply the method selected?**\n",
    "\n",
    "In the case of backwards selection, we must have more observations than variables. Similarly, we must conduct one-hot-encoding on the categorical variables, to ensure that proper variable selection is conducted.\n",
    "Since we are using a linear regression model, we must assume:\n",
    "    1. Linear relation between the variables, tested using a plot of residuals-fitted values\n",
    "    2. Errors are independent (Not a time series)\n",
    "    3. Normal distribution of errors\n",
    "    4. Heteroscedasticity (Equal variance of error terms)\n",
    "Some of these will be tested through the use of residual plots and Q-Q plots post-analysis.\n",
    "\n",
    "\n",
    "> **What are potential limitations or weaknesses of the method selected?**\n",
    "\n",
    "There is the risk that the relationship between our variables are not linear, or that a linear fit does not fit optimally. Similarly, alot of our data is categorical, meaning it may be difficult to produce an accurate linear model, and require encoding, which we are unsure how it will effect the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8157452-a432-4ac6-a2c6-33065082655c",
   "metadata": {},
   "source": [
    "# Methods Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5892541f-76dd-4db9-9077-ea0d0c06123f",
   "metadata": {},
   "source": [
    "Before we begin analysis, we will proceed to remove several low-occurence values, which may have negative affect on the accuracy of our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0601bd57-567f-4f98-888b-ac01efb93ede",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_data <- data %>%\n",
    "    group_by(job_title) %>% \n",
    "    filter(n()>40) \n",
    "\n",
    "new_data <- new_data %>%\n",
    "    group_by(company_location) %>% \n",
    "    filter(n()>10) \n",
    "\n",
    "new_data <- new_data %>%\n",
    "    group_by(employee_residence) %>% \n",
    "    filter(n()>10)\n",
    "\n",
    "# There are only 3 Non-Full-Time observations\n",
    "# More optimal to remove variable\n",
    "new_data <- new_data %>%\n",
    "    select(-employment_type) \n",
    "\n",
    "new_data %>% \n",
    "    summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01547c9-4cd1-4527-a04e-7a55437c143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "\n",
    "# Splitting the dataset 70/30 for testing/training\n",
    "data_split <- initial_split(new_data, prop = 0.7, strata = salary_in_usd)\n",
    "training_set <- training(data_split)\n",
    "testing_set <- testing(data_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f64f0f-9dc0-4e0e-b3b5-0d99061cc9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6d1b0d-1c7e-4287-9141-b9a1cd95f948",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MLR_nonVS <- lm(salary_in_usd~., training_set) \n",
    "summary1 <- summary(MLR_nonVS)\n",
    "summary1$coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d76559-0c7b-4fc4-b07e-f7804074d417",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "glance(summary1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feb4df9-567a-42de-94e8-d714891297b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_prediction1 <- predict(MLR_nonVS, newdata = testing_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08c62d6-b760-4737-a5e8-0a3468db6c97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RMSE_model1 <- tibble(\n",
    "  Model = \"OLS Full Regression\",\n",
    "  RMSE = rmse(\n",
    "    preds = test_prediction1,\n",
    "    actuals = testing_set$salary_in_usd\n",
    "  )\n",
    ")\n",
    "RMSE_model1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83c9f4e-57ab-4576-ab08-c442a70bb143",
   "metadata": {},
   "source": [
    "The RMSE reveals that the average prediction is off by ~$39,594 which is incredibly inaccurate. However this may be the best results we can obtain from this dataset, as there are many outliers as well as categorical variables that make predictions inaccurate. Let's see if variable selection improves this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdc0ba9-a792-4ef6-9e07-acfcd67cc90e",
   "metadata": {},
   "source": [
    "## 2. MLR with One-Hot-Encoding and Backwards Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25ca59f-bdd9-45cf-a669-af6d3bf80744",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One-hot encode categorical variables\n",
    "new_data <- one_hot(as.data.table(new_data))\n",
    "names(new_data)<-make.names(names(new_data),unique = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e8c941-3dbe-4ba8-93e1-79603ca4b45c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "\n",
    "data_split <- initial_split(new_data, prop = 0.7, strata = salary_in_usd)\n",
    "training_set <- training(data_split)\n",
    "testing_set <- testing(data_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2369882-dba5-4924-966f-c249428cba82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_backward_sel <- regsubsets(\n",
    "  nvmax = 75,\n",
    "  x = salary_in_usd ~ .,\n",
    "  data = training_set,\n",
    "  method = \"backward\",\n",
    ")\n",
    "\n",
    "data_backward_summary <- summary(data_backward_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5078bdd0-3b9a-4ba1-8c1a-1c9b7bc4e025",
   "metadata": {},
   "source": [
    "Selection detected linear dependences, so final selection only chooses 20 variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14ef125-cc3b-4c8d-8906-72945643b7ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_backward_summary_df <- tibble(\n",
    "    n_input_variables = 1:20,\n",
    "    RSQ = data_backward_summary$rsq,\n",
    "    RSS = data_backward_summary$rss,\n",
    "    ADJ.R2 = data_backward_summary$adjr2,\n",
    "    Cp = data_backward_summary$cp,\n",
    "    BIC = data_backward_summary$bic,\n",
    "# )%>% arrange(desc(ADJ.R2))\n",
    ") %>% arrange(Cp)\n",
    "\n",
    "head(data_backward_summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30458777-540f-4b23-9248-f1703113ebff",
   "metadata": {},
   "source": [
    "Select the model with the highest Adjusted $R^2$ as we are trying to find best inference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10317c75-4e89-4b97-9e8c-e2cf0b2e8153",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cp_min = which.min(data_backward_summary$cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4c5f0b-a785-4abc-a9ff-44dc044c0cf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_var <- names(coef(data_backward_sel, cp_min))[-1]\n",
    "selected_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9151772-61d7-4953-bc1f-38d8059ed6a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_subset <- training_set %>% select(all_of(selected_var), salary_in_usd)\n",
    "testing_subset <- testing_set %>% select(all_of(selected_var), salary_in_usd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27a2bc3-8cb0-4423-ac23-317fe0eab023",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_MLR <- lm(salary_in_usd ~ .,\n",
    "  data = training_subset\n",
    ")\n",
    "MLR_summary <- summary(data_MLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b313cf14-398a-4bb1-a891-c44701d98a27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tidy(MLR_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904c7f20-97dc-4890-af5a-17cbbe887f9a",
   "metadata": {},
   "source": [
    "We notice that all the coefficients have substantial impact on the estimated values, ranging from approximately -30,000USD to +65,000USD, likewise with massive standard errors. This indicates that the relevant variables chosen for this model, while significant (from p-values), would result in inaccurate predictions that have huge ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fd584e-e8b5-43e9-89c0-ffe8a2d9b9a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "glance(data_MLR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a38dc7-622e-46dd-945f-b4241401fa79",
   "metadata": {},
   "source": [
    "This is further reflected by the `adj.r.squared` value of 0.3242661, which indicates that the model would be poor at predicting new values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5182aa97-c178-4f9c-ba02-b166f6b1ed33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_prediction2 <- predict(data_MLR, newdata = testing_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688f233b-4517-44a0-ab24-db99e658e065",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_model2 <- tibble(\n",
    "  Model = \"OLS Full Regression\",\n",
    "  RMSE = rmse(\n",
    "    preds = test_prediction2,\n",
    "    actuals = testing_subset$salary_in_usd\n",
    "  )\n",
    ")\n",
    "RMSE_model2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0123a2-2d8b-45dc-a5ba-1047720e2647",
   "metadata": {},
   "source": [
    "## Result Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9c00ab-b0c3-4bc5-bde2-fd6efa068ef5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "linear_prediction1 <- data.frame(Predicted = test_prediction1, Observed = testing_set$salary_in_usd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ba5aa5-ee78-49de-a8c0-967936862c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4224f9b-3a77-485a-840f-13a576fd1743",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_model2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4a74fc-edfb-4eef-b705-9d2c0b651dc8",
   "metadata": {},
   "source": [
    "We see that the model without one-hot-encoding and variable selection fairs slightly better comparing RMSE, by approximately $4,000USD. That said both models are quite poor in predicting salaries from the test data. We can analyze some of the plots to get an indication on why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93175ed-1bb4-4039-871b-d03375d27648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig1 <- ggplot(linear_prediction1,\n",
    "               aes(x = Predicted, y = Observed)) +\n",
    "               geom_point() +\n",
    "               geom_abline(intercept = 0,\n",
    "                           slope = 1,\n",
    "                           color = \"red\",\n",
    "                           linewidth = 1)+\n",
    "               ggtitle(\"Predicted vs. Observed Salaries in USD from MLR Model (All Variables)\") +\n",
    "               theme_bw()\n",
    "\n",
    "fig1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d074312b-dd74-42f3-82ce-3b22a62e266f",
   "metadata": {},
   "source": [
    "Analyzing the results we see that both MLR models give poor prediction and low accuracy, with RMSE values of **39594.15** and **40947.49**, showing that the models are on average predicting salaries that are around 40,000 USD away from test values. This can be further seen by the **adjusted** $R^2$ from either model, showing values of **0.56** and **0.44** which is only slightly better than the intercept-only model. We attribute this largely to the fact that the dataset is primarily categorical variables, with data that may not fit well linear models or current methods of variable selection. Future improvements involve using cross-validation to improve model training as well as look into other methods of variable selection such as Lasso or Ridge."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
